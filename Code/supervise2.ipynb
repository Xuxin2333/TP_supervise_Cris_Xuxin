{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dd6750f-4733-4360-905c-9a85c949794d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las bibliotecas necesarias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fe3b1c7-2e79-4109-b8de-eb0ebefa4d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "# X: features, y: labels\n",
    "features = pd.read_csv(\"../JeuDeDonnees/alt_acsincome_ca_features_85(1).csv\")\n",
    "labels = pd.read_csv(\"../JeuDeDonnees/alt_acsincome_ca_labels_85.csv\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1168869e-9ddf-44fb-ab54-26f5c1d84c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print content\n",
    "print(\"DATABASE 1\")\n",
    "print(features.head())\n",
    "print(features.columns)\n",
    "\n",
    "# Delete missing values - NULL, If 'MAR' or 'COW' contain NULL values \n",
    "features['AGEP'].hist(bins=30)\n",
    "plt.title('Age Distribution')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Nb de personnes')\n",
    "plt.show()\n",
    "# Limpiar los datos eliminando filas con valores nulos en 'MAR' y 'COW'\n",
    "features_df = features.dropna(subset=['MAR', 'COW'])\n",
    "\n",
    "# Create relation between 'MAR' and 'COW' \n",
    "features_relation = features_df.groupby(['MAR', 'COW']).size().reset_index(name='QUANTITÉ')\n",
    "print(features_relation)\n",
    "\n",
    "# Create Graphic\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=features_relation, x='MAR', y='QUANTITÉ', hue='COW', palette='viridis')\n",
    "plt.title('Relation entre MAR (État Civil) et COW (Occupation)')\n",
    "plt.xlabel('MAR (État Civil)')\n",
    "plt.ylabel('QUANTITÉ PERSONNES')\n",
    "plt.legend(title='COW (Occupation)')\n",
    "plt.show()\n",
    "\n",
    "print(\"\")\n",
    "print(\"DATABASE 2\")\n",
    "# print(labels.head())  # Show first lines from the dataset\n",
    "print(labels.columns)   # Show all the columns on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b9ccb31-0b8e-4570-9f6a-66b1bae282d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------\n",
      "    SHUFFLE AND DIVIDED DATA   \n",
      "-----------------------------\n",
      "\n",
      "\n",
      "Size TRAINING set: (133052, 10)\n",
      "TRAINING set:\n",
      "        AGEP  COW  SCHL  MAR    OCCP   POBP  RELP  WKHP  SEX  RAC1P\n",
      "0       41.0  4.0  24.0  1.0  2555.0    6.0   1.0  60.0  2.0    1.0\n",
      "1       77.0  7.0  22.0  1.0  4920.0   39.0   0.0  35.0  1.0    1.0\n",
      "2       38.0  1.0  18.0  1.0   440.0    6.0   1.0  50.0  1.0    1.0\n",
      "3       30.0  1.0  22.0  5.0  1555.0    6.0   2.0  80.0  1.0    6.0\n",
      "4       36.0  1.0  16.0  1.0  4030.0  314.0   1.0  70.0  2.0    1.0\n",
      "...      ...  ...   ...  ...     ...    ...   ...   ...  ...    ...\n",
      "133047  47.0  1.0  18.0  1.0  5240.0   47.0   0.0  40.0  2.0    2.0\n",
      "133048  23.0  1.0  18.0  5.0  4720.0    6.0  13.0  30.0  2.0    1.0\n",
      "133049  18.0  1.0  16.0  5.0  4220.0    6.0   2.0  10.0  1.0    8.0\n",
      "133050  41.0  1.0  21.0  1.0  4850.0   29.0   1.0  30.0  1.0    1.0\n",
      "133051  51.0  1.0  19.0  1.0  1010.0    6.0  15.0  40.0  1.0    1.0\n",
      "\n",
      "[133052 rows x 10 columns]\n",
      "\n",
      "Size TEST set: (33263, 10) \n",
      "\n",
      "TEST set:\n",
      "        AGEP  COW  SCHL  MAR    OCCP   POBP  RELP  WKHP  SEX  RAC1P\n",
      "133052  42.0  1.0  13.0  1.0  7330.0    6.0   1.0  35.0  1.0    3.0\n",
      "133053  32.0  1.0  21.0  5.0  2710.0   53.0   0.0  60.0  1.0    1.0\n",
      "133054  18.0  6.0  16.0  5.0  6260.0   53.0  11.0  30.0  1.0    8.0\n",
      "133055  72.0  6.0  21.0  1.0   410.0   39.0   0.0  30.0  1.0    1.0\n",
      "133056  42.0  1.0  19.0  1.0  7700.0  233.0   0.0  40.0  2.0    6.0\n",
      "...      ...  ...   ...  ...     ...    ...   ...   ...  ...    ...\n",
      "166310  25.0  1.0  20.0  1.0  4720.0    6.0   7.0   8.0  2.0    1.0\n",
      "166311  34.0  1.0  22.0  1.0   110.0  210.0   0.0  40.0  1.0    6.0\n",
      "166312  54.0  3.0  18.0  1.0  7700.0    6.0   1.0  50.0  1.0    1.0\n",
      "166313  39.0  1.0  16.0  5.0  9130.0    6.0   0.0  50.0  1.0    1.0\n",
      "166314  32.0  1.0   9.0  5.0  4020.0  303.0   0.0  40.0  2.0    8.0\n",
      "\n",
      "[33263 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n-----------------------------\")\n",
    "print(\"    SHUFFLE AND DIVIDED DATA   \")\n",
    "print(\"-----------------------------\\n\")\n",
    "# Shuffle and Divide data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features,           # X_train - X_test Características (features)\n",
    "    labels.values.ravel(),             # y_train - y_test  (labels)\n",
    "    test_size=0.2,      # Size test set (20%)\n",
    "    random_state=42,    # Para reproducibilidad\n",
    "    shuffle=False       # Mix data TRUE\n",
    ")\n",
    "\n",
    "print(\"\\nSize TRAINING set:\", X_train.shape)\n",
    "print(\"TRAINING set:\")\n",
    "print(X_train) # Print Results\n",
    "\n",
    "print(\"\\nSize TEST set:\", X_test.shape, \"\\n\")\n",
    "print(\"TEST set:\")\n",
    "print(X_test) # Print Results\n",
    "\n",
    "# To standaliser the datas\n",
    "my_scaler = StandardScaler()\n",
    "X_train_Standed = my_scaler.fit_transform(X_train.select_dtypes(include=['float64','int64']))\n",
    "X_test_Standed = my_scaler.fit_transform(X_test.select_dtypes(include=['float64','int64']))\n",
    "joblib.dump (my_scaler, 'my_scaler.joblib')\n",
    "\n",
    "# from sklearn.utils import shuffle\n",
    "datos_shuffled = shuffle(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5ce836-640f-4649-a47b-345a73772a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "# Validation Croisée\n",
    "svm_model = SVC(kernel='linear')\n",
    "scores = cross_val_score(svm_model,X_train,y_train,cv=5).mean()\n",
    "\n",
    "# Accuracy & Classification report & Confusion matrix\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "classification_rep = classification_report(y_test, y_pred_svm)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_svm)\n",
    "\n",
    "# Grid Search for best parameters\n",
    "param_grid = {'C': [0.1, 1, 10, 20], 'kernel': ['rbf', 'poly']}\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(\"best_params = \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "927d792d-01cb-40c5-9310-a5fd81adafb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RandomForest...\n",
      "Accuracy average (Cross Validation): 0.8126\n",
      "Accuracy on test set: 0.8173\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.86      0.85     19774\n",
      "        True       0.78      0.76      0.77     13489\n",
      "\n",
      "    accuracy                           0.82     33263\n",
      "   macro avg       0.81      0.81      0.81     33263\n",
      "weighted avg       0.82      0.82      0.82     33263\n",
      "\n",
      "Confusion Matrix:\n",
      "[[16933  2841]\n",
      " [ 3236 10253]]\n",
      "----------------------------------------\n",
      "Training AdaBoost...\n",
      "Accuracy average (Cross Validation): 0.8042\n",
      "Accuracy on test set: 0.8083\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.83      0.85      0.84     19774\n",
      "        True       0.77      0.75      0.76     13489\n",
      "\n",
      "    accuracy                           0.81     33263\n",
      "   macro avg       0.80      0.80      0.80     33263\n",
      "weighted avg       0.81      0.81      0.81     33263\n",
      "\n",
      "Confusion Matrix:\n",
      "[[16771  3003]\n",
      " [ 3373 10116]]\n",
      "----------------------------------------\n",
      "Training GradientBoosting...\n",
      "Accuracy average (Cross Validation): 0.8138\n",
      "Accuracy on test set: 0.8175\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.85      0.85     19774\n",
      "        True       0.78      0.76      0.77     13489\n",
      "\n",
      "    accuracy                           0.82     33263\n",
      "   macro avg       0.81      0.81      0.81     33263\n",
      "weighted avg       0.82      0.82      0.82     33263\n",
      "\n",
      "Confusion Matrix:\n",
      "[[16891  2883]\n",
      " [ 3188 10301]]\n",
      "----------------------------------------\n",
      "Training SVM...\n",
      "Accuracy average (Cross Validation): 0.7122\n",
      "Accuracy on test set: 0.7174\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.73      0.82      0.78     19774\n",
      "        True       0.69      0.56      0.62     13489\n",
      "\n",
      "    accuracy                           0.72     33263\n",
      "   macro avg       0.71      0.69      0.70     33263\n",
      "weighted avg       0.71      0.72      0.71     33263\n",
      "\n",
      "Confusion Matrix:\n",
      "[[16298  3476]\n",
      " [ 5923  7566]]\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Models to be tested with params by default\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(),\n",
    "    \"SVM\": SVC()\n",
    "}\n",
    "\n",
    "# Cross-validation and initial metrics\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    print(f\"Accuracy average (Cross-Validation): {np.mean(scores):.4f}\")\n",
    "    \n",
    "    # Train and evaluate on the test set\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(f\"Accuracy on test set: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(\"Classification report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4726f1e1-eb95-4c16-930a-ccd1a46cbf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for each model\n",
    "param_grids = {\n",
    "    \"RandomForest\": {\"n_estimators\": [50, 100, 200], \"max_depth\": [None, 10, 20]},\n",
    "    \"AdaBoost\": {\"n_estimators\": [50, 100, 200], \"learning_rate\": [0.01, 0.1, 1]},\n",
    "    \"GradientBoosting\": {\"n_estimators\": [50, 100, 200], \"learning_rate\": [0.01, 0.1, 1]},\n",
    "    \"SVM\": {\"C\": [0.1, 1, 10], \"kernel\": [\"linear\", \"rbf\"]}\n",
    "}\n",
    "\n",
    "# Optimize each model\n",
    "best_models = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"Optimización de hyperparameters for {name}...\")\n",
    "    grid = GridSearchCV(model, param_grids[name], cv=5, scoring='accuracy')\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_models[name] = grid.best_estimator_\n",
    "    \n",
    "    print(f\"Best Parameters for {name}: {grid.best_params_}\")\n",
    "    print(f\"Best Accuracy (Cross-validation): {grid.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4654929-a13a-4356-a7ae-2adfa9ace05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking model accuracy with SVM: 0.792953131106635\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.81      0.85      0.83     19774\n",
      "        True       0.76      0.72      0.74     13489\n",
      "\n",
      "    accuracy                           0.79     33263\n",
      "   macro avg       0.79      0.78      0.78     33263\n",
      "weighted avg       0.79      0.79      0.79     33263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training SVM with the results of the base models.\n",
    "# Training Models with the best hyperparameters\n",
    "rf = RandomForestClassifier(n_estimators=200, max_depth=20)\n",
    "gb = GradientBoostingClassifier(n_estimators=200, learning_rate=1)\n",
    "ab = AdaBoostClassifier(n_estimators=200, learning_rate=1)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "gb.fit(X_train, y_train)\n",
    "ab.fit(X_train, y_train)\n",
    "\n",
    "# Generate predictions as features for the SVM - Train set\n",
    "rf_preds = rf.predict_proba(X_train)[:, 1]\n",
    "gb_preds = gb.predict_proba(X_train)[:, 1]\n",
    "ab_preds = ab.predict_proba(X_train)[:, 1]\n",
    "\n",
    "X_train_stack = np.column_stack((rf_preds, gb_preds, ab_preds))\n",
    "\n",
    "# Generate predictions as features for the SVM - Test set\n",
    "rf_preds_test = rf.predict_proba(X_test)[:, 1]\n",
    "gb_preds_test = gb.predict_proba(X_test)[:, 1]\n",
    "ab_preds_test = ab.predict_proba(X_test)[:, 1]\n",
    "\n",
    "X_test_stack = np.column_stack((rf_preds_test, gb_preds_test, ab_preds_test))\n",
    "\n",
    "# Training SVM lineal as meta-model\n",
    "svm = LinearSVC(C=1, max_iter=10000, random_state=42)\n",
    "svm.fit(X_train_stack, y_train)\n",
    "\n",
    "# Evaluation\n",
    "y_pred = svm.predict(X_test_stack)\n",
    "\n",
    "print(\"Stacking model accuracy with SVM:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4953cbc-12f0-43b1-977b-328c0d536981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate and save the best models\n",
    "for name, model in best_models.items():\n",
    "    print(f\"Evaluation of the optimized model: {name}\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(f\"Accuracy on test set: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(\"Classification report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    # Save Model\n",
    "    filename = f\"{name}_BestModel_{accuracy_score(y_test, y_pred):.4f}\".replace(\".\", \"\") + \".joblib\"\n",
    "    joblib.dump(model, filename)\n",
    "    print(f\"Model saved as: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864e0f6b-028e-4ce0-8bb2-0ed734cbf5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Forest \n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "cv_scores_rf = cross_val_score(rf_model, X_train, y_train, cv=5).mean()\n",
    "print(\"validation croisée average score = \", cv_scores_rf)\n",
    "\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "classification_rep_rf = classification_report(y_test, y_pred_rf)\n",
    "conf_matrix_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "\n",
    "\n",
    "param_grid_rf = {'n_estimators': [50, 100, 120],'criterion':['gini','entropy','log_loss'],'max_depth': [None, 10, 20],'min_samples_split':[0.1, 1.0, 2]}\n",
    "grid_search_rf = GridSearchCV(RandomForestClassifier(), param_grid_rf, cv=5)\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "best_params_rf = grid_search_rf.best_params_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "115ae328-e07b-4c5a-abc5-bf0ed76773f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models to be tested with params by default\n",
    "models2 = {\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(),\n",
    "    \"SVM\": SVC()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c961ef-a5ea-4121-b52a-35d911b74575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimización de hiperparámetros para GradientBoosting...\n"
     ]
    }
   ],
   "source": [
    "# Hiperparámetros para cada modelo\n",
    "param_grids = {\n",
    "    \"GradientBoosting\": {\"n_estimators\": [50, 100, 200], \"learning_rate\": [0.01, 0.1, 1]},\n",
    "    \"SVM\": {\"C\": [0.1, 1, 10], \"kernel\": [\"linear\", \"rbf\"]}\n",
    "}\n",
    "\n",
    "# Optimizar cada modelo\n",
    "best_models = {}\n",
    "for name, model in models2.items():\n",
    "    print(f\"Optimización de hiperparámetros para {name}...\")\n",
    "    grid = GridSearchCV(model, param_grids[name], cv=5, scoring='accuracy')\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_models[name] = grid.best_estimator_\n",
    "    \n",
    "    print(f\"Mejores parámetros para {name}: {grid.best_params_}\")\n",
    "    print(f\"Mejor precisión (validación cruzada): {grid.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b70fe37-df8c-428a-afdc-14e88797c3b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f0e3c9-873b-4229-8977-4a942b148a8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
