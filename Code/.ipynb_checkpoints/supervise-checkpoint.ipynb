{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6dd6750f-4733-4360-905c-9a85c949794d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las bibliotecas necesarias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3fe3b1c7-2e79-4109-b8de-eb0ebefa4d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "# X: features, y: labels\n",
    "features = pd.read_csv(\"../JeuDeDonnees/alt_acsincome_ca_features_85(1).csv\")\n",
    "labels = pd.read_csv(\"../JeuDeDonnees/alt_acsincome_ca_labels_85.csv\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1168869e-9ddf-44fb-ab54-26f5c1d84c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print content\n",
    "print(\"DATABASE 1\")\n",
    "print(features.head())\n",
    "print(features.columns)\n",
    "\n",
    "# Delete missing values - NULL, If 'MAR' or 'COW' contain NULL values \n",
    "features['AGEP'].hist(bins=30)\n",
    "plt.title('Age Distribution')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Nb de personnes')\n",
    "plt.show()\n",
    "# Limpiar los datos eliminando filas con valores nulos en 'MAR' y 'COW'\n",
    "features_df = features.dropna(subset=['MAR', 'COW'])\n",
    "\n",
    "# Create relation between 'MAR' and 'COW' \n",
    "features_relation = features_df.groupby(['MAR', 'COW']).size().reset_index(name='QUANTITÉ')\n",
    "print(features_relation)\n",
    "\n",
    "# Create Graphic\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=features_relation, x='MAR', y='QUANTITÉ', hue='COW', palette='viridis')\n",
    "plt.title('Relation entre MAR (État Civil) et COW (Occupation)')\n",
    "plt.xlabel('MAR (État Civil)')\n",
    "plt.ylabel('QUANTITÉ PERSONNES')\n",
    "plt.legend(title='COW (Occupation)')\n",
    "plt.show()\n",
    "\n",
    "print(\"\")\n",
    "print(\"DATABASE 2\")\n",
    "# print(labels.head())  # Show first lines from the dataset\n",
    "print(labels.columns)   # Show all the columns on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3b9ccb31-0b8e-4570-9f6a-66b1bae282d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------\n",
      "    SHUFFLE AND DIVIDED DATA   \n",
      "-----------------------------\n",
      "\n",
      "\n",
      "Size TRAINING set: (133052, 10)\n",
      "TRAINING set:\n",
      "        AGEP  COW  SCHL  MAR    OCCP   POBP  RELP  WKHP  SEX  RAC1P\n",
      "0       41.0  4.0  24.0  1.0  2555.0    6.0   1.0  60.0  2.0    1.0\n",
      "1       77.0  7.0  22.0  1.0  4920.0   39.0   0.0  35.0  1.0    1.0\n",
      "2       38.0  1.0  18.0  1.0   440.0    6.0   1.0  50.0  1.0    1.0\n",
      "3       30.0  1.0  22.0  5.0  1555.0    6.0   2.0  80.0  1.0    6.0\n",
      "4       36.0  1.0  16.0  1.0  4030.0  314.0   1.0  70.0  2.0    1.0\n",
      "...      ...  ...   ...  ...     ...    ...   ...   ...  ...    ...\n",
      "133047  47.0  1.0  18.0  1.0  5240.0   47.0   0.0  40.0  2.0    2.0\n",
      "133048  23.0  1.0  18.0  5.0  4720.0    6.0  13.0  30.0  2.0    1.0\n",
      "133049  18.0  1.0  16.0  5.0  4220.0    6.0   2.0  10.0  1.0    8.0\n",
      "133050  41.0  1.0  21.0  1.0  4850.0   29.0   1.0  30.0  1.0    1.0\n",
      "133051  51.0  1.0  19.0  1.0  1010.0    6.0  15.0  40.0  1.0    1.0\n",
      "\n",
      "[133052 rows x 10 columns]\n",
      "\n",
      "Size TEST set: (33263, 10) \n",
      "\n",
      "TEST set:\n",
      "        AGEP  COW  SCHL  MAR    OCCP   POBP  RELP  WKHP  SEX  RAC1P\n",
      "133052  42.0  1.0  13.0  1.0  7330.0    6.0   1.0  35.0  1.0    3.0\n",
      "133053  32.0  1.0  21.0  5.0  2710.0   53.0   0.0  60.0  1.0    1.0\n",
      "133054  18.0  6.0  16.0  5.0  6260.0   53.0  11.0  30.0  1.0    8.0\n",
      "133055  72.0  6.0  21.0  1.0   410.0   39.0   0.0  30.0  1.0    1.0\n",
      "133056  42.0  1.0  19.0  1.0  7700.0  233.0   0.0  40.0  2.0    6.0\n",
      "...      ...  ...   ...  ...     ...    ...   ...   ...  ...    ...\n",
      "166310  25.0  1.0  20.0  1.0  4720.0    6.0   7.0   8.0  2.0    1.0\n",
      "166311  34.0  1.0  22.0  1.0   110.0  210.0   0.0  40.0  1.0    6.0\n",
      "166312  54.0  3.0  18.0  1.0  7700.0    6.0   1.0  50.0  1.0    1.0\n",
      "166313  39.0  1.0  16.0  5.0  9130.0    6.0   0.0  50.0  1.0    1.0\n",
      "166314  32.0  1.0   9.0  5.0  4020.0  303.0   0.0  40.0  2.0    8.0\n",
      "\n",
      "[33263 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n-----------------------------\")\n",
    "print(\"    SHUFFLE AND DIVIDED DATA   \")\n",
    "print(\"-----------------------------\\n\")\n",
    "# Shuffle and Divide data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features,           # X_train - X_test Características (features)\n",
    "    labels.values.ravel(),             # y_train - y_test  (labels)\n",
    "    test_size=0.2,      # Size test set (20%)\n",
    "    random_state=42,    # Para reproducibilidad\n",
    "    shuffle=False       # Mix data TRUE\n",
    ")\n",
    "\n",
    "print(\"\\nSize TRAINING set:\", X_train.shape)\n",
    "print(\"TRAINING set:\")\n",
    "print(X_train) # Print Results\n",
    "\n",
    "print(\"\\nSize TEST set:\", X_test.shape, \"\\n\")\n",
    "print(\"TEST set:\")\n",
    "print(X_test) # Print Results\n",
    "\n",
    "# To standaliser the datas\n",
    "my_scaler = StandardScaler()\n",
    "X_train_Standed = my_scaler.fit_transform(X_train.select_dtypes(include=['float64','int64']))\n",
    "X_test_Standed = my_scaler.fit_transform(X_test.select_dtypes(include=['float64','int64']))\n",
    "joblib.dump (my_scaler, 'my_scaler.joblib')\n",
    "\n",
    "# from sklearn.utils import shuffle\n",
    "datos_shuffled = shuffle(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5ce836-640f-4649-a47b-345a73772a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "# Validation Croisée\n",
    "svm_model = SVC(kernel='linear')\n",
    "scores = cross_val_score(svm_model,X_train,y_train,cv=5).mean()\n",
    "\n",
    "# Accuracy & Classification report & Confusion matrix\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "classification_rep = classification_report(y_test, y_pred_svm)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_svm)\n",
    "\n",
    "# Grid Search for best parameters\n",
    "param_grid = {'C': [0.1, 1, 10, 20], 'kernel': ['rbf', 'poly']}\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(\"best_params = \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bcf6cec-6f5b-4f4e-95ed-cb2103bda40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models to be tested with params by default\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(),\n",
    "    \"SVM\": SVC()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "927d792d-01cb-40c5-9310-a5fd81adafb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RandomForest...\n",
      "Accuracy average (Cross Validation): 0.8126\n",
      "Accuracy on test set: 0.8173\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.86      0.85     19774\n",
      "        True       0.78      0.76      0.77     13489\n",
      "\n",
      "    accuracy                           0.82     33263\n",
      "   macro avg       0.81      0.81      0.81     33263\n",
      "weighted avg       0.82      0.82      0.82     33263\n",
      "\n",
      "Confusion Matrix:\n",
      "[[16933  2841]\n",
      " [ 3236 10253]]\n",
      "----------------------------------------\n",
      "Training AdaBoost...\n",
      "Accuracy average (Cross Validation): 0.8042\n",
      "Accuracy on test set: 0.8083\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.83      0.85      0.84     19774\n",
      "        True       0.77      0.75      0.76     13489\n",
      "\n",
      "    accuracy                           0.81     33263\n",
      "   macro avg       0.80      0.80      0.80     33263\n",
      "weighted avg       0.81      0.81      0.81     33263\n",
      "\n",
      "Confusion Matrix:\n",
      "[[16771  3003]\n",
      " [ 3373 10116]]\n",
      "----------------------------------------\n",
      "Training GradientBoosting...\n",
      "Accuracy average (Cross Validation): 0.8138\n",
      "Accuracy on test set: 0.8175\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.85      0.85     19774\n",
      "        True       0.78      0.76      0.77     13489\n",
      "\n",
      "    accuracy                           0.82     33263\n",
      "   macro avg       0.81      0.81      0.81     33263\n",
      "weighted avg       0.82      0.82      0.82     33263\n",
      "\n",
      "Confusion Matrix:\n",
      "[[16891  2883]\n",
      " [ 3188 10301]]\n",
      "----------------------------------------\n",
      "Training SVM...\n",
      "Accuracy average (Cross Validation): 0.7122\n",
      "Accuracy on test set: 0.7174\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.73      0.82      0.78     19774\n",
      "        True       0.69      0.56      0.62     13489\n",
      "\n",
      "    accuracy                           0.72     33263\n",
      "   macro avg       0.71      0.69      0.70     33263\n",
      "weighted avg       0.71      0.72      0.71     33263\n",
      "\n",
      "Confusion Matrix:\n",
      "[[16298  3476]\n",
      " [ 5923  7566]]\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation and initial metrics\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    print(f\"Accuracy average (Cross-Validation): {np.mean(scores):.4f}\")\n",
    "    \n",
    "    # Train and evaluate on the test set\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(f\"Accuracy on test set: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(\"Classification report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e82cdb74-684f-41ba-a52c-d0c69d875727",
   "metadata": {},
   "outputs": [],
   "source": [
    "models2 = {\n",
    "    #RandomForest\": RandomForestClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    #\"GradientBoosting\": GradientBoostingClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4726f1e1-eb95-4c16-930a-ccd1a46cbf16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimización de hyperparameters for RandomForest...\n",
      "Best Parameters for RandomForest: {'max_depth': 20, 'n_estimators': 200}\n",
      "Best Accuracy (Cross-validation): 0.8179\n",
      "Optimización de hyperparameters for AdaBoost...\n",
      "Best Parameters for AdaBoost: {'learning_rate': 1, 'n_estimators': 200}\n",
      "Best Accuracy (Cross-validation): 0.8091\n",
      "Optimización de hyperparameters for GradientBoosting...\n",
      "Best Parameters for GradientBoosting: {'learning_rate': 1, 'n_estimators': 200}\n",
      "Best Accuracy (Cross-validation): 0.8229\n",
      "Optimización de hyperparameters for SVM...\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters for each model\n",
    "param_grids = {\n",
    "    \"RandomForest\": {\"n_estimators\": [50, 100, 200], \"max_depth\": [None, 10, 20]},\n",
    "    \"AdaBoost\": {\"n_estimators\": [50, 100, 200], \"learning_rate\": [0.01, 0.1, 1]},\n",
    "    \"GradientBoosting\": {\"n_estimators\": [50, 100, 200], \"learning_rate\": [0.01, 0.1, 1]},\n",
    "    \"SVM\": {\"C\": [0.1, 1, 10], \"kernel\": [\"linear\", \"rbf\"]}\n",
    "}\n",
    "\n",
    "# Optimize each model\n",
    "best_models = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"Optimización de hyperparameters for {name}...\")\n",
    "    grid = GridSearchCV(model, param_grids[name], cv=5, scoring='accuracy')\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_models[name] = grid.best_estimator_\n",
    "    \n",
    "    print(f\"Best Parameters for {name}: {grid.best_params_}\")\n",
    "    print(f\"Best Accuracy (Cross-validation): {grid.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d4654929-a13a-4356-a7ae-2adfa9ace05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of the optimized model: SVM\n",
      "Stacking model accuracy with SVM: 0.7939452244235337\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.81      0.85      0.83     19774\n",
      "        True       0.76      0.72      0.74     13489\n",
      "\n",
      "    accuracy                           0.79     33263\n",
      "   macro avg       0.79      0.78      0.78     33263\n",
      "weighted avg       0.79      0.79      0.79     33263\n",
      "\n",
      "Confusion Matrix:\n",
      "[[16737  3037]\n",
      " [ 3817  9672]]\n",
      "Model saved as: SVM_BestModel_07939.joblib\n"
     ]
    }
   ],
   "source": [
    "# Training SVM with the results of the base models.\n",
    "# Training Models with the best hyperparameters\n",
    "rf = RandomForestClassifier(n_estimators=200, max_depth=20)\n",
    "gb = GradientBoostingClassifier(n_estimators=200, learning_rate=1)\n",
    "ab = AdaBoostClassifier(n_estimators=200, learning_rate=1)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "gb.fit(X_train, y_train)\n",
    "ab.fit(X_train, y_train)\n",
    "\n",
    "best_models[\"RandomForest\"] = rf\n",
    "best_models[\"GradientBoosting\"] = gb\n",
    "best_models[\"AdaBoost\"] = ab\n",
    "\n",
    "# Generate predictions as features for the SVM - Train set\n",
    "rf_preds = rf.predict_proba(X_train)[:, 1]\n",
    "gb_preds = gb.predict_proba(X_train)[:, 1]\n",
    "ab_preds = ab.predict_proba(X_train)[:, 1]\n",
    "\n",
    "X_train_stack = np.column_stack((rf_preds, gb_preds, ab_preds))\n",
    "\n",
    "# Generate predictions as features for the SVM - Test set\n",
    "rf_preds_test = rf.predict_proba(X_test)[:, 1]\n",
    "gb_preds_test = gb.predict_proba(X_test)[:, 1]\n",
    "ab_preds_test = ab.predict_proba(X_test)[:, 1]\n",
    "\n",
    "X_test_stack = np.column_stack((rf_preds_test, gb_preds_test, ab_preds_test))\n",
    "\n",
    "# Training SVM lineal as meta-model\n",
    "svm = LinearSVC(C=1, max_iter=10000, random_state=42)\n",
    "svm.fit(X_train_stack, y_train)\n",
    "\n",
    "# Add this model to the best models\n",
    "best_models[\"SVM_Stacking\"] = svm\n",
    "\n",
    "# Evaluation\n",
    "y_pred = svm.predict(X_test_stack)\n",
    "print(f\"Evaluation of the optimized model: SVM\")\n",
    "print(\"Stacking model accuracy with SVM:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Save Model\n",
    "filename = f\"SVM_BestModel_{accuracy_score(y_test, y_pred):.4f}\".replace(\".\", \"\") + \".joblib\"\n",
    "joblib.dump(model, filename)\n",
    "print(f\"Model saved as: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57b014a1-0759-4c38-9ee9-df21d777db1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content BestModels\n",
      "RandomForest: RandomForestClassifier(max_depth=20, n_estimators=200)\n",
      "AdaBoost: AdaBoostClassifier(learning_rate=1, n_estimators=200)\n",
      "GradientBoosting: GradientBoostingClassifier(learning_rate=1, n_estimators=200)\n"
     ]
    }
   ],
   "source": [
    "print(\"Content BestModels\")\n",
    "for name, model in best_models.items():\n",
    "    print(f\"{name}: {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9713d3a4-4165-4051-804e-09cbbaad79e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of the optimized model: RandomForest\n",
      "Accuracy on test set: 0.8233\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.86      0.85     19774\n",
      "        True       0.79      0.77      0.78     13489\n",
      "\n",
      "    accuracy                           0.82     33263\n",
      "   macro avg       0.82      0.82      0.82     33263\n",
      "weighted avg       0.82      0.82      0.82     33263\n",
      "\n",
      "Confusion Matrix:\n",
      "[[16943  2831]\n",
      " [ 3048 10441]]\n",
      "Model saved as: RandomForest_BestModel_08233.joblib\n",
      "Evaluation of the optimized model: AdaBoost\n",
      "Accuracy on test set: 0.8134\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.85      0.84     19774\n",
      "        True       0.78      0.76      0.77     13489\n",
      "\n",
      "    accuracy                           0.81     33263\n",
      "   macro avg       0.81      0.80      0.81     33263\n",
      "weighted avg       0.81      0.81      0.81     33263\n",
      "\n",
      "Confusion Matrix:\n",
      "[[16813  2961]\n",
      " [ 3247 10242]]\n",
      "Model saved as: AdaBoost_BestModel_08134.joblib\n",
      "Evaluation of the optimized model: GradientBoosting\n",
      "Accuracy on test set: 0.8223\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.85      0.85     19774\n",
      "        True       0.78      0.78      0.78     13489\n",
      "\n",
      "    accuracy                           0.82     33263\n",
      "   macro avg       0.82      0.82      0.82     33263\n",
      "weighted avg       0.82      0.82      0.82     33263\n",
      "\n",
      "Confusion Matrix:\n",
      "[[16798  2976]\n",
      " [ 2935 10554]]\n",
      "Model saved as: GradientBoosting_BestModel_08223.joblib\n"
     ]
    }
   ],
   "source": [
    "# Evaluate and save the best models\n",
    "for name, model in best_models.items():\n",
    "    print(f\"Evaluation of the optimized model: {name}\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(f\"Accuracy on test set: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(\"Classification report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    # Saved Model\n",
    "    filename = f\"{name}_BestModel_{accuracy_score(y_test, y_pred):.4f}\".replace(\".\", \"\") + \".joblib\"\n",
    "    joblib.dump(model, filename)\n",
    "    print(f\"Model saved as: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46fc0784-b04b-4e42-b347-50b0904a0b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter optimization for RandomForest...\n",
      "Best parameters for RandomForest: {'max_depth': 15, 'n_estimators': 400}\n",
      "Best accuracy (cross-validation): 0.8183\n",
      "Hyperparameter optimization for AdaBoost...\n",
      "Best parameters for AdaBoost: {'learning_rate': 1.2, 'n_estimators': 500}\n",
      "Best accuracy (cross-validation): 0.8148\n",
      "Hyperparameter optimization for GradientBoosting...\n",
      "Best parameters for GradientBoosting: {'learning_rate': 0.5, 'n_estimators': 400}\n",
      "Best accuracy (cross-validation): 0.8256\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters for each model\n",
    "param_grids = {\n",
    "    \"RandomForest\": {\"n_estimators\": [300, 400, 500], \"max_depth\": [15, 20, 25]},\n",
    "    \"AdaBoost\": {\"n_estimators\": [300, 400, 500], \"learning_rate\": [0.5, 1, 1.2]},\n",
    "    \"GradientBoosting\": {\"n_estimators\": [300, 400, 500], \"learning_rate\": [0.05, 0.5, 1]}\n",
    "}\n",
    "\n",
    "# Optimize each model\n",
    "best_models = {}\n",
    "for name, model in models2.items():\n",
    "    print(f\"Hyperparameter optimization for {name}...\")\n",
    "    grid = GridSearchCV(model, param_grids[name], cv=5, scoring='accuracy')\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_models[name] = grid.best_estimator_\n",
    "    \n",
    "    print(f\"Best parameters for {name}: {grid.best_params_}\")\n",
    "    print(f\"Best accuracy (cross-validation): {grid.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f7bd9fbf-547a-4f26-95aa-94402f683998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of the optimized model: SVM\n",
      "Stacking model accuracy with SVM: 0.8148393109460963\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.83      0.86      0.85     19774\n",
      "        True       0.78      0.75      0.77     13489\n",
      "\n",
      "    accuracy                           0.81     33263\n",
      "   macro avg       0.81      0.80      0.81     33263\n",
      "weighted avg       0.81      0.81      0.81     33263\n",
      "\n",
      "Confusion Matrix:\n",
      "[[16987  2787]\n",
      " [ 3372 10117]]\n",
      "Model saved as: SVM_BestModel_08148.joblib\n"
     ]
    }
   ],
   "source": [
    "# Training SVM with the results of the base models.\n",
    "# Training Models with the best hyperparameters\n",
    "rf = RandomForestClassifier(n_estimators=400, max_depth=15)\n",
    "gb = GradientBoostingClassifier(n_estimators=500, learning_rate=1.2)\n",
    "ab = AdaBoostClassifier(n_estimators=400, learning_rate=0.5)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "gb.fit(X_train, y_train)\n",
    "ab.fit(X_train, y_train)\n",
    "\n",
    "best_models[\"RandomForest\"] = rf\n",
    "best_models[\"GradientBoosting\"] = gb\n",
    "best_models[\"AdaBoost\"] = ab\n",
    "\n",
    "# Generate predictions as features for the SVM - Train set\n",
    "rf_preds = rf.predict_proba(X_train)[:, 1]\n",
    "gb_preds = gb.predict_proba(X_train)[:, 1]\n",
    "ab_preds = ab.predict_proba(X_train)[:, 1]\n",
    "\n",
    "X_train_stack = np.column_stack((rf_preds, gb_preds, ab_preds))\n",
    "\n",
    "# Generate predictions as features for the SVM - Test set\n",
    "rf_preds_test = rf.predict_proba(X_test)[:, 1]\n",
    "gb_preds_test = gb.predict_proba(X_test)[:, 1]\n",
    "ab_preds_test = ab.predict_proba(X_test)[:, 1]\n",
    "\n",
    "X_test_stack = np.column_stack((rf_preds_test, gb_preds_test, ab_preds_test))\n",
    "\n",
    "# Training SVM lineal as meta-model\n",
    "svm = LinearSVC(C=1, max_iter=10000, random_state=42)\n",
    "svm.fit(X_train_stack, y_train)\n",
    "\n",
    "# Evaluation\n",
    "y_pred = svm.predict(X_test_stack)\n",
    "print(f\"Evaluation of the optimized model: SVM\")\n",
    "print(\"Stacking model accuracy with SVM:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Save Model\n",
    "filename = f\"SVM_BestModel_{accuracy_score(y_test, y_pred):.4f}\".replace(\".\", \"\") + \".joblib\"\n",
    "joblib.dump(model, filename)\n",
    "print(f\"Model saved as: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f2dce459-b8b4-4351-8fb2-35da4906f35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content BestModels\n",
      "RandomForest: RandomForestClassifier(max_depth=15, n_estimators=400)\n",
      "AdaBoost: AdaBoostClassifier(learning_rate=0.5, n_estimators=400)\n",
      "GradientBoosting: GradientBoostingClassifier(learning_rate=1.2, n_estimators=500)\n"
     ]
    }
   ],
   "source": [
    "print(\"Content BestModels\")\n",
    "for name, model in best_models.items():\n",
    "    print(f\"{name}: {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b4953cbc-12f0-43b1-977b-328c0d536981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of the optimized model: RandomForest\n",
      "Accuracy on test set: 0.8235\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.86      0.85     19774\n",
      "        True       0.79      0.78      0.78     13489\n",
      "\n",
      "    accuracy                           0.82     33263\n",
      "   macro avg       0.82      0.82      0.82     33263\n",
      "weighted avg       0.82      0.82      0.82     33263\n",
      "\n",
      "Confusion Matrix:\n",
      "[[16910  2864]\n",
      " [ 3008 10481]]\n",
      "Model saved as: RandomForest_BestModel_08235.joblib\n",
      "Evaluation of the optimized model: AdaBoost\n",
      "Accuracy on test set: 0.8110\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.83      0.85      0.84     19774\n",
      "        True       0.78      0.75      0.76     13489\n",
      "\n",
      "    accuracy                           0.81     33263\n",
      "   macro avg       0.80      0.80      0.80     33263\n",
      "weighted avg       0.81      0.81      0.81     33263\n",
      "\n",
      "Confusion Matrix:\n",
      "[[16872  2902]\n",
      " [ 3385 10104]]\n",
      "Model saved as: AdaBoost_BestModel_08110.joblib\n",
      "Evaluation of the optimized model: GradientBoosting\n",
      "Accuracy on test set: 0.8249\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.86      0.85     19774\n",
      "        True       0.79      0.78      0.78     13489\n",
      "\n",
      "    accuracy                           0.82     33263\n",
      "   macro avg       0.82      0.82      0.82     33263\n",
      "weighted avg       0.82      0.82      0.82     33263\n",
      "\n",
      "Confusion Matrix:\n",
      "[[16910  2864]\n",
      " [ 2959 10530]]\n",
      "Model saved as: GradientBoosting_BestModel_08249.joblib\n"
     ]
    }
   ],
   "source": [
    "# Evaluate and save the best models\n",
    "for name, model in best_models.items():\n",
    "    print(f\"Evaluation of the optimized model: {name}\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(f\"Accuracy on test set: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(\"Classification report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    # Save Model\n",
    "    filename = f\"{name}_BestModel_{accuracy_score(y_test, y_pred):.4f}\".replace(\".\", \"\") + \".joblib\"\n",
    "    joblib.dump(model, filename)\n",
    "    print(f\"Model saved as: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "71bc20c1-e5dd-41d0-8118-8864e73d361c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimización de hyperparameters for RandomForest...\n",
      "Best Parameters for RandomForest: {'max_depth': 20, 'min_samples_split': 5, 'n_estimators': 600}\n",
      "Best Accuracy (Cross-validation): 0.8191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimización de hyperparameters for AdaBoost...\n",
      "Best Parameters for AdaBoost: {'estimator': DecisionTreeClassifier(max_depth=2), 'learning_rate': 1.2, 'n_estimators': 600}\n",
      "Best Accuracy (Cross-validation): 0.8190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimización de hiperparámetros para GradientBoosting...\n",
      "Mejores parámetros para GradientBoosting: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 600}\n",
      "Mejor precisión (validación cruzada): 0.8267\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters for each model\n",
    "param_grids = {\n",
    "    #\"RandomForest\": {\"n_estimators\": [200, 400, 600], \"max_depth\": [15, 20, 30], \"min_samples_split\": [2, 5]},\n",
    "    \"AdaBoost\": {\"n_estimators\": [200, 500, 600], \"learning_rate\": [0.8, 1, 1.2], \"estimator\": [DecisionTreeClassifier(max_depth=1), DecisionTreeClassifier(max_depth=2)]},\n",
    "    #\"GradientBoosting\": {\"n_estimators\": [200, 400, 600], \"learning_rate\": [0.05, 0.5, 1], \"max_depth\": [3, 5]},\n",
    "}\n",
    "\n",
    "# Optimize each model\n",
    "best_models = {}\n",
    "for name, model in models2.items():\n",
    "    print(f\"Optimización de hyperparameters for {name}...\")\n",
    "    grid = GridSearchCV(model, param_grids[name], cv=5, scoring='accuracy')\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_models[name] = grid.best_estimator_\n",
    "    \n",
    "    print(f\"Best Parameters for {name}: {grid.best_params_}\")\n",
    "    print(f\"Best Accuracy (Cross-validation): {grid.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b8f51321-d569-4eb8-a713-0a913ec0b5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of the optimized model: SVM\n",
      "Stacking model accuracy with SVM: 0.786489492829871\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.81      0.83      0.82     19774\n",
      "        True       0.75      0.72      0.73     13489\n",
      "\n",
      "    accuracy                           0.79     33263\n",
      "   macro avg       0.78      0.78      0.78     33263\n",
      "weighted avg       0.79      0.79      0.79     33263\n",
      "\n",
      "Confusion Matrix:\n",
      "[[16484  3290]\n",
      " [ 3812  9677]]\n",
      "Model saved as: SVM_BestModel_07865.joblib\n"
     ]
    }
   ],
   "source": [
    "# Training SVM with the results of the base models.\n",
    "# Training Models with the best hyperparameters\n",
    "rf = RandomForestClassifier(n_estimators=600, max_depth=20, min_samples_split= 5)\n",
    "gb = GradientBoostingClassifier(n_estimators=600, learning_rate=0.05, max_depth= 5)\n",
    "ab = AdaBoostClassifier(n_estimators=600, learning_rate=1.2, estimator= DecisionTreeClassifier(max_depth=2))\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "gb.fit(X_train, y_train)\n",
    "ab.fit(X_train, y_train)\n",
    "\n",
    "best_models[\"RandomForest\"] = rf\n",
    "best_models[\"GradientBoosting\"] = gb\n",
    "best_models[\"AdaBoost\"] = ab\n",
    "\n",
    "# Generate predictions as features for the SVM - Train set\n",
    "rf_preds = rf.predict_proba(X_train)[:, 1]\n",
    "gb_preds = gb.predict_proba(X_train)[:, 1]\n",
    "ab_preds = ab.predict_proba(X_train)[:, 1]\n",
    "\n",
    "X_train_stack = np.column_stack((rf_preds, gb_preds, ab_preds))\n",
    "\n",
    "# Generate predictions as features for the SVM - Test set\n",
    "rf_preds_test = rf.predict_proba(X_test)[:, 1]\n",
    "gb_preds_test = gb.predict_proba(X_test)[:, 1]\n",
    "ab_preds_test = ab.predict_proba(X_test)[:, 1]\n",
    "\n",
    "X_test_stack = np.column_stack((rf_preds_test, gb_preds_test, ab_preds_test))\n",
    "\n",
    "# Training SVM lineal as meta-model\n",
    "svm = LinearSVC(C=1, max_iter=10000, random_state=42)\n",
    "svm.fit(X_train_stack, y_train)\n",
    "\n",
    "# Evaluation\n",
    "y_pred = svm.predict(X_test_stack)\n",
    "print(f\"Evaluation of the optimized model: SVM\")\n",
    "print(\"Stacking model accuracy with SVM:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Save Model\n",
    "filename = f\"SVM_BestModel_{accuracy_score(y_test, y_pred):.4f}\".replace(\".\", \"\") + \".joblib\"\n",
    "joblib.dump(model, filename)\n",
    "print(f\"Model saved as: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "02aff2ac-6f3e-4ed5-9626-5cb806e03e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content BestModels\n",
      "AdaBoost: AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=2),\n",
      "                   learning_rate=1.2, n_estimators=600)\n",
      "RandomForest: RandomForestClassifier(max_depth=20, min_samples_split=5, n_estimators=600)\n",
      "GradientBoosting: GradientBoostingClassifier(learning_rate=0.05, max_depth=5, n_estimators=600)\n"
     ]
    }
   ],
   "source": [
    "print(\"Content BestModels\")\n",
    "for name, model in best_models.items():\n",
    "    print(f\"{name}: {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cddc73e9-2f88-45e0-9b3b-4a7338b5fbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of the optimized model: AdaBoost\n",
      "Accuracy on test set: 0.8213\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.85      0.85     19774\n",
      "        True       0.78      0.77      0.78     13489\n",
      "\n",
      "    accuracy                           0.82     33263\n",
      "   macro avg       0.82      0.81      0.81     33263\n",
      "weighted avg       0.82      0.82      0.82     33263\n",
      "\n",
      "Confusion Matrix:\n",
      "[[16897  2877]\n",
      " [ 3067 10422]]\n",
      "Model saved as: AdaBoost_BestModel_08213.joblib\n",
      "Evaluation of the optimized model: RandomForest\n",
      "Accuracy on test set: 0.8243\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.86      0.85     19774\n",
      "        True       0.79      0.77      0.78     13489\n",
      "\n",
      "    accuracy                           0.82     33263\n",
      "   macro avg       0.82      0.82      0.82     33263\n",
      "weighted avg       0.82      0.82      0.82     33263\n",
      "\n",
      "Confusion Matrix:\n",
      "[[16969  2805]\n",
      " [ 3039 10450]]\n",
      "Model saved as: RandomForest_BestModel_08243.joblib\n",
      "Evaluation of the optimized model: GradientBoosting\n",
      "Accuracy on test set: 0.8296\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.86      0.86      0.86     19774\n",
      "        True       0.79      0.79      0.79     13489\n",
      "\n",
      "    accuracy                           0.83     33263\n",
      "   macro avg       0.82      0.82      0.82     33263\n",
      "weighted avg       0.83      0.83      0.83     33263\n",
      "\n",
      "Confusion Matrix:\n",
      "[[16945  2829]\n",
      " [ 2840 10649]]\n",
      "Model saved as: GradientBoosting_BestModel_08296.joblib\n"
     ]
    }
   ],
   "source": [
    "# Evaluate and save the best models\n",
    "for name, model in best_models.items():\n",
    "    print(f\"Evaluation of the optimized model: {name}\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(f\"Accuracy on test set: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(\"Classification report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    # Save Model\n",
    "    filename = f\"{name}_BestModel_{accuracy_score(y_test, y_pred):.4f}\".replace(\".\", \"\") + \".joblib\"\n",
    "    joblib.dump(model, filename)\n",
    "    print(f\"Model saved as: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864e0f6b-028e-4ce0-8bb2-0ed734cbf5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Forest \n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "cv_scores_rf = cross_val_score(rf_model, X_train, y_train, cv=5).mean()\n",
    "print(\"validation croisée average score = \", cv_scores_rf)\n",
    "\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "classification_rep_rf = classification_report(y_test, y_pred_rf)\n",
    "conf_matrix_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "\n",
    "\n",
    "param_grid_rf = {'n_estimators': [50, 100, 120],'criterion':['gini','entropy','log_loss'],'max_depth': [None, 10, 20],'min_samples_split':[0.1, 1.0, 2]}\n",
    "grid_search_rf = GridSearchCV(RandomForestClassifier(), param_grid_rf, cv=5)\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "best_params_rf = grid_search_rf.best_params_\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
